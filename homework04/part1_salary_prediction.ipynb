{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: LIBRARY_PATH=/usr/local/cuda/lib64\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env LIBRARY_PATH=/usr/local/cuda/lib64\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser(\"~/.local/lib/python3.6/site-packages/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pandas import ewma\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Deep Learning\n",
    "\n",
    "__This is exactly the same notebook as in `../week10_textconv/.`__\n",
    "\n",
    "__Feel free submit the seminar notebook, just make sure you read the assignments at the end.__\n",
    "\n",
    "Today we're gonna apply the newly learned DL tools for sequence processing to the task of predicting job salary.\n",
    "\n",
    "Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the assignment core (orignally written for theano/tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the challenge\n",
    "For starters, let's download the data from __[here](https://yadi.sk/d/vVEOWPFY3NruT7)__.\n",
    "\n",
    "You can also get it from the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (in that case, pick `Train_rev1.*`).\n",
    "\n",
    "\n",
    "Our task is to predict one number, __SalaryNormalized__, in the sense of minimizing __Mean Absolute Error__.\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
    "\n",
    "To do so, our model ca access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__.\n",
    "\n",
    "\n",
    "You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33485</th>\n",
       "      <td>68181437</td>\n",
       "      <td>Senior Business Analyst</td>\n",
       "      <td>Senior Business Analyst Location: Crawley, Wes...</td>\n",
       "      <td>Crawley, West Sussex</td>\n",
       "      <td>Crawley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>Capita Resourcing</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>0 - 350/day</td>\n",
       "      <td>42000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.645449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180441</th>\n",
       "      <td>71575921</td>\n",
       "      <td>Rents Intervention Officer</td>\n",
       "      <td>A fantastic opportunity has arisen for a Rents...</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>full_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blackpool Coastal Housing</td>\n",
       "      <td>Other/General Jobs</td>\n",
       "      <td>17,161 - 19,126 per annum</td>\n",
       "      <td>18143</td>\n",
       "      <td>Jobcentre Plus</td>\n",
       "      <td>9.806095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237737</th>\n",
       "      <td>72603979</td>\n",
       "      <td>Head of Sales Commercial Markets</td>\n",
       "      <td>Managing a team of field sales executives and ...</td>\n",
       "      <td>South East</td>\n",
       "      <td>South East London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sales Jobs</td>\n",
       "      <td>80k - 90k</td>\n",
       "      <td>85000</td>\n",
       "      <td>simplysalesjobs.co.uk</td>\n",
       "      <td>11.350418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                             Title  \\\n",
       "33485   68181437           Senior Business Analyst   \n",
       "180441  71575921        Rents Intervention Officer   \n",
       "237737  72603979  Head of Sales Commercial Markets   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "33485   Senior Business Analyst Location: Crawley, Wes...   \n",
       "180441  A fantastic opportunity has arisen for a Rents...   \n",
       "237737  Managing a team of field sales executives and ...   \n",
       "\n",
       "                 LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "33485   Crawley, West Sussex            Crawley          NaN     contract   \n",
       "180441             Blackpool          Blackpool    full_time          NaN   \n",
       "237737            South East  South East London          NaN    permanent   \n",
       "\n",
       "                          Company            Category  \\\n",
       "33485           Capita Resourcing             IT Jobs   \n",
       "180441  Blackpool Coastal Housing  Other/General Jobs   \n",
       "237737                        NaN          Sales Jobs   \n",
       "\n",
       "                        SalaryRaw  SalaryNormalized             SourceName  \\\n",
       "33485                 0 - 350/day             42000       cv-library.co.uk   \n",
       "180441  17,161 - 19,126 per annum             18143         Jobcentre Plus   \n",
       "237737                  80k - 90k             85000  simplysalesjobs.co.uk   \n",
       "\n",
       "        Log1pSalary  \n",
       "33485     10.645449  \n",
       "180441     9.806095  \n",
       "237737    11.350418  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.expanduser(\"~/data/DL_data/Train_rev1.csv\"), index_col=None)\n",
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast nan to string\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The NLP part\n",
    "\n",
    "To even begin training our neural network, we're gonna need to preprocess the text features: tokenize it and build the token vocabularies.\n",
    "\n",
    "Since it is not an NLP course, we're gonna use simple built-in NLTK tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0         Engineering Systems Analyst\n",
      "100000                   HR Assistant\n",
      "200000           Senior EC&I Engineer\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Before\")\n",
    "print(data[\"Title\"][::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "for col in text_columns:\n",
    "    data[col] = data[col].apply(lambda l: ' '.join(tokenizer.tokenize(str(l).lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After\n",
      "0         engineering systems analyst\n",
      "100000                   hr assistant\n",
      "200000         senior ec & i engineer\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"After\")\n",
    "print(data[\"Title\"][::100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's see how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" fields\n",
    "for col in text_columns:\n",
    "    for line in data[col]:\n",
    "        token_counts.update(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f5f42e49c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f425e1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "\n",
    "_=plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.1__ Get a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = list(filter(lambda x: token_counts[x] >= min_count, token_counts))\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens left: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens left:\", len(tokens))\n",
    "assert type(tokens)==list\n",
    "assert len(tokens) in range(32000,35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.2__ Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {token: index for index, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into torch-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For pretrained embeddings\n",
    "##############################\n",
    "from torchtext.vocab import Vocab\n",
    "vocab = Vocab(token_counts, vectors=\"glove.twitter.27B.200d\", vectors_cache=\"/home/shirobokov/data/LSML_data/\",\n",
    "              specials=[\"UNK\", \"PAD\"], min_freq=10)\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [vocab.stoi[word] for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[   2    3    4    1    1]\n",
      " [ 998  176    1    1    1]\n",
      " [  18 3472  242   59    6]]\n"
     ]
    }
   ],
   "source": [
    "#### print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement tf-idf, target averaging or pseudo-counter-based encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data science part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  220291\n",
      "Validation size =  24477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(data, batch_size=None, replace=True, max_len=None):\n",
    "    \"\"\"\n",
    "    Creates a pytorch-friendly dict from the batch data.\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    if batch_size is not None:\n",
    "        data = data.sample(batch_size, replace=replace)\n",
    "    \n",
    "    batch = {}\n",
    "    for col in text_columns:\n",
    "        batch[col] = as_matrix(data[col].values, max_len)\n",
    "    \n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'FullDescription': array([[ 3199,   558,  5782,    73,    54,   179,    55,   386,   388,\n",
       "            86],\n",
       "        [  176,    88,  1433,  2404,  1617,    55,    92,  3162,  1314,\n",
       "          1464],\n",
       "        [33282,   559,  2241,  8024,    15, 14566,     9,  2756,   279,\n",
       "            73]], dtype=int32),\n",
       " 'Log1pSalary': array([10.002473, 10.021315, 10.225607], dtype=float32),\n",
       " 'Title': array([[  54,  179,   55,  386,  388,  214,  428],\n",
       "        [ 176,   48,   88,   92,   74,   82,    1],\n",
       "        [ 246, 1732,  247,    1,    1,    1,    1]], dtype=int32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(data_train, 3, max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's talk deep learning\n",
    "\n",
    "Out model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "![scheme](https://github.com/yandexdataschool/Practical_DL/raw/master/homework04/conv_salary_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, both text vectorizers shall use 1d convolutions, followed by global pooling over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class GlobalMaxPooling(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.max(dim=self.dim, keepdim=True)[0]\n",
    "    \n",
    "class GlobalAveragePooling(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.mean(dim=self.dim, keepdim=True)  \n",
    "    \n",
    "class GlobalKMaxPooling(nn.Module):\n",
    "    def __init__(self, dim=-1, k_max=3):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.k_max = k_max\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, ind = x.topk(k=self.k_max, dim=self.dim)\n",
    "        ind_sorted = ind.sort(dim=self.dim)[0]\n",
    "        return x.gather(self.dim, ind_sorted)\n",
    "    \n",
    "class SoftMaxPooling(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "            super(self.__class__, self).__init__()\n",
    "            self.dim = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (x * F.softmax(x, dim=self.dim)).sum(dim=self.dim, keepdim=True)\n",
    "    \n",
    "    \n",
    "class AttentivePooling(nn.Module):\n",
    "    def __init__(self, input_size, dim=-1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Conv1d(input_size, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_conved = self.nn(x)\n",
    "        return (x * F.softmax(x_conved, dim=self.dim)).sum(dim=self.dim, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TitleEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64):\n",
    "        \"\"\" \n",
    "        A simple sequential encoder for titles.\n",
    "        x -> emb -> conv -> global_max -> relu -> dense\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        emb_size = 64\n",
    "        self.emb = nn.Embedding(n_tokens, emb_size, padding_idx=PAD_IX)\n",
    "        self.conv1 = nn.Conv1d(emb_size, out_size, kernel_size=3, padding=1)\n",
    "        \n",
    "        #self.pool1 = GlobalMaxPooling()\n",
    "        #self.pool2 = GlobalAveragePooling()\n",
    "        self.pool1 = SoftMaxPooling()\n",
    "        self.pool3 = AttentivePooling(out_size)\n",
    "        self.pool4 = AttentivePooling(out_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(emb_size, 32, num_layers=1, bidirectional=True)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(256)\n",
    "        self.dense = nn.Linear(256, out_size)\n",
    "\n",
    "    def forward(self, text_ix):\n",
    "        \"\"\"\n",
    "        :param text_ix: int64 Variable of shape [batch_size, max_len]\n",
    "        :returns: float32 Variable of shape [batch_size, out_size]\n",
    "        \"\"\"\n",
    "        h = self.emb(text_ix)\n",
    "\n",
    "        # we transpose from [batch, time, units] to [batch, units, time] to fit Conv1d dim order\n",
    "        h = torch.transpose(h, 1, 2)\n",
    "        \n",
    "        # Apply the layers as defined above. Add some ReLUs before dense.\n",
    "        out = self.conv1(h)\n",
    "        \n",
    "        lstm_out , _ = self.lstm(torch.transpose(h, 1, 2))\n",
    "        lstm_out = torch.transpose(lstm_out, 1, 2)\n",
    "        \n",
    "        pool_list = []\n",
    "        pool_list.append(self.pool1(out))\n",
    "        pool_list.append(self.pool3(out))\n",
    "        \n",
    "        pool_list.append(self.pool1(lstm_out))\n",
    "        pool_list.append(self.pool4(lstm_out))\n",
    "        #print([k.shape for k in pool_list])\n",
    "#         print(out_1.shape, out_2[..., None].shape)\n",
    "#         print(torch.cat([out_1, out_2[..., None]], dim=-1).shape)\n",
    "        out = torch.cat(pool_list, dim=-1).view(h.shape[0], -1)\n",
    "        out = self.bn(out)\n",
    "\n",
    "        out = F.relu(out)\n",
    "        out = self.dense(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine\n"
     ]
    }
   ],
   "source": [
    "t_out_size = 64\n",
    "title_encoder = TitleEncoder(out_size=t_out_size)\n",
    "\n",
    "dummy_x = Variable(torch.LongTensor(generate_batch(data_train, 3)['Title']))\n",
    "dummy_v = title_encoder(dummy_x)\n",
    "\n",
    "assert isinstance(dummy_v, Variable)\n",
    "assert tuple(dummy_v.shape) == (dummy_x.shape[0], t_out_size)\n",
    "\n",
    "del title_encoder\n",
    "print(\"Seems fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.1__ Create description encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define an encoder for job descriptions.\n",
    "# Use any means you want so long as it's torch.nn.Module.\n",
    "class DescEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64):\n",
    "        \"\"\" \n",
    "        A simple sequential encoder for titles.\n",
    "        x -> emb -> conv -> global_max -> relu -> dense\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        emb_size = 64\n",
    "        \n",
    "        self.emb = nn.Embedding(n_tokens, emb_size, padding_idx=PAD_IX)\n",
    "        self.conv1 = nn.Conv1d(emb_size, out_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(emb_size, out_size, kernel_size=5, padding=2)\n",
    "        #self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        #self.conv4 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.pool1 = SoftMaxPooling()\n",
    "        self.pool2 = AttentivePooling(2 * out_size)\n",
    "\n",
    "        #self.pool3 = AttentivePooling(2 * out_size)        \n",
    "        \n",
    "        #self.lstm = nn.LSTM(64, 128, num_layers=2, bidirectional=True, dropout=0.3)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(256)\n",
    "        self.dense = nn.Linear(256, out_size)\n",
    "\n",
    "    def forward(self, text_ix):\n",
    "        \"\"\"\n",
    "        :param text_ix: int64 Variable of shape [batch_size, max_len]\n",
    "        :returns: float32 Variable of shape [batch_size, out_size]\n",
    "        \"\"\"\n",
    "        h = self.emb(text_ix)\n",
    "\n",
    "        # we transpose from [batch, time, units] to [batch, units, time] to fit Conv1d dim order\n",
    "        h = torch.transpose(h, 1, 2)\n",
    "        \n",
    "        # Apply the layers as defined above. Add some ReLUs before dense.\n",
    "        \n",
    "        # Parallell convs\n",
    "        out_1 = self.conv1(h)\n",
    "        out_2 = self.conv2(h)\n",
    "        \n",
    "        out = torch.cat([out_1, out_2], dim=1)\n",
    "        \n",
    "        #LSTM part\n",
    "#         lstm_out , _ = self.lstm(torch.transpose(h, 1, 2))\n",
    "#         lstm_out = torch.transpose(lstm_out, 1, 2)    \n",
    "    \n",
    "        # Pool all part\n",
    "        pool_list = []\n",
    "        pool_list.append(self.pool1(out))\n",
    "        pool_list.append(self.pool2(out))\n",
    "#         pool_list.append(self.pool1(lstm_out))\n",
    "#         pool_list.append(self.pool3(lstm_out))\n",
    "\n",
    "        out = torch.cat(pool_list, dim=-1).view(h.shape[0], -1)\n",
    "        \n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dense(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine too\n"
     ]
    }
   ],
   "source": [
    "d_out_size = 64\n",
    "desc_encoder = DescEncoder(out_size=d_out_size)\n",
    "\n",
    "dummy_x = Variable(torch.LongTensor(generate_batch(data_train, 3)['FullDescription']))\n",
    "dummy_v = desc_encoder(dummy_x)\n",
    "\n",
    "assert isinstance(dummy_v, Variable)\n",
    "assert tuple(dummy_v.shape) == (dummy_x.shape[0], d_out_size)\n",
    "del desc_encoder\n",
    "print(\"Seems fine too\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Task 2.2__ Build one network ~~to rule them all~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This class does all the steps from (title, desc, categorical) features -> predicted target\n",
    "    It unites title & desc encoders you defined above as long as some layers for head and categorical branch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_)):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.title_out_size = 64\n",
    "        self.desc_out_size = 64\n",
    "        self.cat_out_size = 128\n",
    "        self.total_output_size = self.title_out_size + self.desc_out_size + self.cat_out_size\n",
    "        \n",
    "        self.title_encoder = TitleEncoder(out_size=self.title_out_size)\n",
    "        self.desc_encoder = DescEncoder(out_size=self.desc_out_size)\n",
    "        \n",
    "        \n",
    "        # define layers for categorical features. A few dense layers would do.\n",
    "        self.categorical_encoder = nn.Sequential(\n",
    "            nn.Linear(n_cat_features, self.cat_out_size),\n",
    "            nn.BatchNorm1d(self.cat_out_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.cat_out_size, self.cat_out_size)\n",
    "        )\n",
    "        \n",
    "        # define \"output\" layers that process depend the three encoded vectors into answer\n",
    "        self.mixed_output = nn.Sequential(\n",
    "            nn.Linear(self.total_output_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, title_ix, desc_ix, cat_features):\n",
    "        \"\"\"\n",
    "        :param title_ix: int32 Variable [batch, title_len], job titles encoded by as_matrix\n",
    "        :param desc_ix:  int32 Variable [batch, desc_len] , job descriptions encoded by as_matrix\n",
    "        :param cat_features: float32 Variable [batch, n_cat_features]\n",
    "        :returns: float32 Variable 1d [batch], predicted log1p-salary\n",
    "        \"\"\"\n",
    "        \n",
    "        # process each data source with it's respective encoder\n",
    "        title_h = self.title_encoder(title_ix)\n",
    "        desc_h = self.desc_encoder(desc_ix)\n",
    "        \n",
    "        # apply categorical encoder\n",
    "        cat_h = self.categorical_encoder(cat_features)\n",
    "        \n",
    "        # concatenate all vectors together...\n",
    "        joint_h = torch.cat([title_h, desc_h, cat_h], dim=1)\n",
    "        \n",
    "        # ... and stack a few more layers at the top\n",
    "        out = self.mixed_output(joint_h)\n",
    "        \n",
    "        # Note 1: do not forget to select first columns, [:, 0], to get to 1d outputs\n",
    "        # Note 2: please do not use output nonlinearities.\n",
    "        \n",
    "        return out[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = FullNetwork()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test it on one batch\n",
    "\n",
    "batch = generate_batch(data_train, 32)\n",
    "\n",
    "title_ix = Variable(torch.LongTensor(batch[\"Title\"]))\n",
    "desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"]))\n",
    "cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"]))\n",
    "reference = Variable(torch.FloatTensor(batch[target_column]))\n",
    "\n",
    "prediction = model(title_ix, desc_ix, cat_features)\n",
    "\n",
    "assert len(prediction.shape) == 1 and prediction.shape[0] == title_ix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(reference, prediction):\n",
    "    \"\"\"\n",
    "    Computes objective for minimization.\n",
    "    By deafult we minimize MSE, but you are encouraged to try mix up MSE, MAE, huber loss, etc.\n",
    "    \"\"\"\n",
    "    return torch.mean((prediction - reference) ** 2)\n",
    "    #return torch.abs(torch.exp(reference - 1) - torch.exp(prediction - 1)).mean()\n",
    "\n",
    "def compute_mae(reference, prediction):\n",
    "    \"\"\" Compute MAE on actual salary, assuming your model outputs log1p(salary)\"\"\"\n",
    "    return torch.abs(torch.exp(reference - 1) - torch.exp(prediction - 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = compute_loss(reference, prediction)\n",
    "dummy_grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n",
    "for grad in dummy_grads:\n",
    "    assert grad is not None and not (grad == 0).all(), \"Some model parameters received zero grads. \" \\\n",
    "                                                       \"Double-check that your model uses all it's layers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def iterate_minibatches(data, batch_size=32, max_len=None,\n",
    "                        max_batches=None, shuffle=True, verbose=True):\n",
    "    indices = np.arange(len(data))\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(indices)\n",
    "    if max_batches is not None:\n",
    "        indices = indices[: batch_size * max_batches]\n",
    "        \n",
    "    #irange = tnrange if verbose else range\n",
    "    \n",
    "    for start in tqdm(range(0, len(indices), batch_size), total=len(indices) / batch_size):\n",
    "        yield generate_batch(data.iloc[indices[start : start + batch_size]], max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "global BEST_EPOCH\n",
    "BEST_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, opt, num_epochs, max_len, batch_size, batches_per_epoch, best_mae=1e5): \n",
    "    for epoch_i in range(num_epochs):\n",
    "        start_time = time.time() \n",
    "        print(\"Training:\")\n",
    "        train_loss = train_mae = train_batches = 0    \n",
    "        model.train(True)\n",
    "\n",
    "        for batch in iterate_minibatches(data_train, max_batches=batches_per_epoch, max_len=max_len):\n",
    "\n",
    "            title_ix = Variable(torch.LongTensor(batch[\"Title\"]))\n",
    "            desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"]))\n",
    "            cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"]))\n",
    "            reference = Variable(torch.FloatTensor(batch[target_column]))\n",
    "\n",
    "            title_ix, desc_ix, cat_features, reference = list(map(lambda x: x.cuda(),\n",
    "                                                              [title_ix, desc_ix, cat_features, reference]))        \n",
    "\n",
    "            prediction = model(title_ix, desc_ix, cat_features)\n",
    "\n",
    "            loss = compute_loss(reference, prediction)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            train_loss += loss.data.cpu().numpy()[0]\n",
    "            train_mae += compute_mae(reference, prediction).data.cpu().numpy()[0]\n",
    "            train_batches += 1\n",
    "\n",
    "\n",
    "        train_loss_history.append(train_loss / train_batches)\n",
    "        train_mae_history.append(train_mae / train_batches)\n",
    "\n",
    "        print(\"Validation:\")\n",
    "        val_loss = val_mae = val_batches = 0\n",
    "        model.train(False)\n",
    "\n",
    "        for batch in iterate_minibatches(data_val, shuffle=False, max_len=max_len):\n",
    "            title_ix = Variable(torch.LongTensor(batch[\"Title\"]), volatile=True)\n",
    "            desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"]), volatile=True)\n",
    "            cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"]), volatile=True)\n",
    "            reference = Variable(torch.FloatTensor(batch[target_column]), volatile=True)\n",
    "\n",
    "            title_ix, desc_ix, cat_features, reference = list(map(lambda x: x.cuda(),\n",
    "                                                             [title_ix, desc_ix, cat_features, reference]))\n",
    "\n",
    "            prediction = model(title_ix, desc_ix, cat_features)\n",
    "            loss = compute_loss(reference, prediction)\n",
    "\n",
    "            val_loss += loss.data.cpu().numpy()[0]\n",
    "            val_mae += compute_mae(reference, prediction).data.cpu().numpy()[0]\n",
    "            val_batches += 1\n",
    "\n",
    "        val_loss_history.append(val_loss / val_batches)\n",
    "        val_mae_history.append(val_mae / val_batches)        \n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        #plt.figure(figsize=(8, 6))\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,6))\n",
    "        ax1.set_title(\"Loss\")\n",
    "        ax1.set_xlabel(\"#Epoch\")\n",
    "        ax1.set_ylabel(\"loss\")\n",
    "        ax1.plot(train_loss_history, 'b', label='Train loss')\n",
    "        ax1.plot(val_loss_history, 'r', label='Val loss')\n",
    "        #ax1.plot(ewma(np.array(train_loss), span=10),'r',label='ewm val loss')\n",
    "        ax1.legend(loc='best')\n",
    "        ax1.grid()\n",
    "        ax1.set_ylim(0, 1)\n",
    "\n",
    "        ax2.set_title(\"MAE\")\n",
    "        ax2.set_xlabel(\"#Epoch\")\n",
    "        ax2.set_ylabel(\"MAE\")\n",
    "        ax2.plot(train_mae_history, 'b', label='Train mae')\n",
    "        ax2.plot(val_mae_history, 'r', label='Val mae')\n",
    "        #ax2.plot(ewma(np.array(val_loss), span=10),'r',label='ewm val acc')\n",
    "        ax2.legend(loc='best')\n",
    "        ax2.grid()    \n",
    "        ax2.set_ylim(1800, 10000)\n",
    "        \n",
    "        plt.show() \n",
    "\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch_i + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss_history[-1]))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_loss_history[-1]))\n",
    "\n",
    "        print(\"  training mae (in-iteration): \\t{:.3f}\".format(train_mae_history[-1]))\n",
    "        print(\"  validation mae:\\t\\t{:.3f}\".format(val_mae_history[-1]))    \n",
    "        \n",
    "        ## Save best epoch\n",
    "        if val_mae_history[-1] < best_mae:\n",
    "            best_mae = val_mae_history[-1]\n",
    "            best_epoch = epoch_i\n",
    "            BEST_EPOCH = best_epoch\n",
    "            with open ('best_val_state_dict.pt', 'wb') as f:\n",
    "                torch.save(model.state_dict(), f)\n",
    "\n",
    "        if epoch_i - best_epoch > 30:\n",
    "            print (\"Best epoch:{0}, val MAE:{1}\".format(best_epoch, best_mae))\n",
    "            return best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Actually make it work\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__.\n",
    "\n",
    "Try __at least 3 options__ from the list below for a passing grade. If you're into \n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `nn.BatchNorm1d`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to do max pooling:\n",
    "* Max over time - our `GlobalMaxPooling`\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a small neural network\n",
    "\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$\n",
    "\n",
    "#### C) Fun with embeddings\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained word2vec from [here](http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/) or [here](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/).\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "  * Please bear in mind that while convolution uses [batch, units, time] dim order, \n",
    "    recurrent units are built for [batch, time, unit]. You may need to `torch.transpose`.\n",
    "\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [keras](https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L461) for inspiration.\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.state_dict`\n",
    "  * Plotting learning curves is usually a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "max_len = 100\n",
    "batch_size = 512\n",
    "batches_per_epoch = None\n",
    "\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "model = FullNetwork().cuda()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_mae_history = []\n",
    "val_mae_history = []       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opt = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAGDCAYAAAD5+0frAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e5c9d8908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/6884.09375 [00:00<18:05,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 of 100 took 615.536s\n",
      "  training loss (in-iteration): \t0.018509\n",
      "  validation loss:\t\t0.051009\n",
      "  training mae (in-iteration): \t1380.425\n",
      "  validation mae:\t\t1999.378\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/6884.09375 [00:06<10:41, 10.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-90e357118ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-ca883b60f35f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, num_epochs, max_len, batch_size, batches_per_epoch, best_mae)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                               [title_ix, desc_ix, cat_features, reference]))        \n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-8ad46f5bc327>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, title_ix, desc_ix, cat_features)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# process each data source with it's respective encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtitle_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mdesc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-f795e8e68a2f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_ix)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shirobokov/.local/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             ))\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_epoch = train(model, opt, num_epochs, max_len, batch_size, batches_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAGDCAYAAAD5+0frAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO/8fgXxnlPzO/lEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e88063c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,6))\n",
    "ax1.set_title(\"Loss\")\n",
    "ax1.set_xlabel(\"#Epoch\")\n",
    "ax1.set_ylabel(\"loss\")\n",
    "ax1.plot(train_loss_history, 'b', label='Train loss')\n",
    "ax1.plot(val_loss_history, 'r', label='Val loss')\n",
    "#ax1.plot(ewma(np.array(train_loss), span=10),'r',label='ewm val loss')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "ax2.set_title(\"MAE\")\n",
    "ax2.set_xlabel(\"#Epoch\")\n",
    "ax2.set_ylabel(\"MAE\")\n",
    "ax2.plot(train_mae_history, 'b', label='Train mae')\n",
    "ax2.plot(val_mae_history, 'r', label='Val mae')\n",
    "#ax2.plot(ewma(np.array(val_loss), span=10),'r',label='ewm val acc')\n",
    "ax2.legend(loc='best')\n",
    "ax2.grid()    \n",
    "ax2.set_ylim(1000, 10000)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = FullNetwork()\n",
    "final_model.load_state_dict(torch.load(\"best_val_state_dict.pt\"))\n",
    "final_model = final_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/764.90625 [00:00<00:46, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "765it [00:51, 14.89it/s]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.04883\n",
      "\tMAE:\t1898.67588\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Final eval:\")\n",
    "val_loss = val_mae = val_batches = 0\n",
    "\n",
    "for batch in iterate_minibatches(data_val, shuffle=False, max_len=100):\n",
    "    title_ix = Variable(torch.LongTensor(batch[\"Title\"]), volatile=True)\n",
    "    desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"]), volatile=True)\n",
    "    cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"]), volatile=True)\n",
    "    reference = Variable(torch.FloatTensor(batch[target_column]), volatile=True)\n",
    "    \n",
    "    title_ix, desc_ix, cat_features, reference = list(map(lambda x: x.cuda(),\n",
    "                                                     [title_ix, desc_ix, cat_features, reference]))    \n",
    "\n",
    "    prediction = final_model(title_ix, desc_ix, cat_features)\n",
    "    loss = compute_loss(reference, prediction)\n",
    "\n",
    "    val_loss += loss.data.cpu().numpy()[0]\n",
    "    val_mae += compute_mae(reference, prediction).data.cpu().numpy()[0]\n",
    "    val_batches += 1\n",
    "\n",
    "print(\"\\tLoss:\\t%.5f\" % (val_loss / val_batches))\n",
    "print(\"\\tMAE:\\t%.5f\" % (val_mae / val_batches))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case of GloVe\n",
    "###############\n",
    "model = FullNetwork(n_tokens=len(vocab))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "\n",
    "embed_size = 200\n",
    "vocab_size = len(vocab)\n",
    "sd = 1/np.sqrt(embed_size)  # Standard deviation to use\n",
    "weights = np.random.normal(0, scale=sd, size=[vocab_size, embed_size])\n",
    "weights = weights.astype(np.float32)\n",
    "\n",
    "for word, index in vocab.stoi.items():\n",
    "    if vocab.vectors[index].sum():\n",
    "        weights[index, :] = vocab.vectors[index]\n",
    "\n",
    "model.title_encoder.emb.weight.data = torch.Tensor(weights)\n",
    "model.desc_encoder.emb.weight.data = torch.Tensor(weights)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = train(model, opt, num_epochs, max_len, batch_size, batches_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n",
    "\n",
    "`<YOUR_TEXT_HERE>`, i guess..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The inital setup(seminar) MAE was about 3000 in my case.\n",
    "- I have started with simplest case and implemented point A: added batchnorms, dropout, parallel convs to description encoder. This provided me with about 100 MAE improvement.\n",
    "- Then, I decided to increase ```batch_size = 256``` and ```batches_per_epoch = 256```. This, actually, provided me with the most delta of improvement I got - validation MAE drop dramatically to 2500.\n",
    "- Afterwards, I have implemented LSTM model for both Description and Title encoder, and broke the rule of one change at time. Result was worse. So, finally, after playing with LSTMs I left only one, in Title enocder, making biderectional(of course, since we know the hole sentence), but left with 1 layer. LSTM Also gave me imporovement about at 100.\n",
    "- Finally, I played with poolings, and implemented different kinds of them: Average pooling, KMaxPooling, Softmax and Attention poolings. In the final version, I took concatenation of two types of poolings. This also gave me about 100 MAE. So at this point the final MAE was about 2300 with 100 epochs optimisation.\n",
    "- Finally, I left the network to train for longer and ended up with 2200 MAE. Althought, early stopping does not help me in my case, since the final model was the last one. What could be added at this stage is learning rate decay, which currently is not there.\n",
    "- Actually, one important moment was to switch training to train all all training data per epoch, that give a enormous boost. One can see on the plots above, that with such approach, I achieved val MAE ~ 2000 for about 20 epochs. This change resulted in final mae in about 1900!. Also, I capped max_len at final validation, since it's a choice of person, how he wants to clamp output matrix encoding.\n",
    "- Afterwards I tried embeddings(GloVe from torchtext package), but did not feel much of change in behaviour, and decided not to continue with them to save time.\n",
    "\n",
    "So, I have implemented 5/5 proposed improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
