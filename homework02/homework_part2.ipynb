{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will build a monster network to solve CIFAR10 image classification.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +10% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 50% (50% points)\n",
    "    * 60% (60% points)\n",
    "    * 65% (70% points)\n",
    "    * 70% (80% points)\n",
    "    * 75% (90% points)\n",
    "    * 80% (full points)\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 80%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the e-mail). After that, you can use whatever you want.\n",
    "* you __can__ use validation data for training, but you __can't'__ do anything with test data apart from running the evaluation procedure.\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=path_to_cifar_like_in_seminar, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "   \n",
    "There is a template for your solution below that you can opt to use or throw away and write it your way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: LIBRARY_PATH=/usr/local/cuda/lib64\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env LIBRARY_PATH=/usr/local/cuda/lib64\n",
    "import sys\n",
    "sys.path.append(\"/home/shirobokov/.local/lib/python3.6/site-packages/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3, 32, 32) (10000, 3, 32, 32) (10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "from cifar import load_cifar10\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_cifar10(\"/home/shirobokov/data/cifar_data\")\n",
    "class_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
    "\n",
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu_1): ReLU()\n",
       "  (dropout_1): Dropout(p=0.3)\n",
       "  (conv_5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool_5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu_5): ReLU()\n",
       "  (dropout_5): Dropout(p=0.3)\n",
       "  (conv_2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool_2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu_2): ReLU()\n",
       "  (dropout_2): Dropout(p=0.3)\n",
       "  (conv_3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool_3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu_3): ReLU()\n",
       "  (dropout_3): Dropout(p=0.5)\n",
       "  (flat): Flatten(\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (relu_4): ReLU()\n",
       "  (dropout_4): Dropout(p=0.3)\n",
       "  (fc_f): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (relu_f): ReLU()\n",
       "  (fc_final): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential()\n",
    "model.add_module('conv_1', nn.Conv2d(3, 64, kernel_size=(3,3), stride=1, padding=0))\n",
    "#model.add_module(\"maxpool_1\", torch.nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\"bn1\", torch.nn.BatchNorm2d(64))\n",
    "model.add_module(\"relu_1\", torch.nn.ReLU())\n",
    "model.add_module('dropout_1', nn.Dropout(p=0.3))\n",
    "\n",
    "model.add_module('conv_5', nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=0))\n",
    "model.add_module(\"maxpool_5\", torch.nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\"bn5\", torch.nn.BatchNorm2d(64))\n",
    "model.add_module(\"relu_5\", torch.nn.ReLU())\n",
    "model.add_module('dropout_5', nn.Dropout(p=0.3))\n",
    "\n",
    "model.add_module('conv_2', nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=0))\n",
    "model.add_module(\"maxpool_2\", torch.nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\"bn2\", torch.nn.BatchNorm2d(128))\n",
    "model.add_module(\"relu_2\", torch.nn.ReLU())\n",
    "model.add_module('dropout_2', nn.Dropout(p=0.3))\n",
    "\n",
    "model.add_module('conv_3', nn.Conv2d(128, 256, kernel_size=(3,3), stride=1, padding=0))\n",
    "model.add_module(\"maxpool_3\", torch.nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\"bn3\", torch.nn.BatchNorm2d(256))\n",
    "model.add_module(\"relu_3\", torch.nn.ReLU())\n",
    "model.add_module('dropout_3', nn.Dropout(p=0.5))          \n",
    "\n",
    "model.add_module(\"flat\", Flatten())\n",
    "\n",
    "model.add_module(\"fc1\", torch.nn.Linear(1024, 1024))\n",
    "model.add_module(\"relu_4\", torch.nn.ReLU())\n",
    "model.add_module(\"dropout_4\", torch.nn.Dropout(p=0.3))\n",
    "\n",
    "model.add_module(\"fc_f\", torch.nn.Linear(1024, 512))\n",
    "model.add_module(\"relu_f\", torch.nn.ReLU())\n",
    "model.add_module(\"fc_final\", torch.nn.Linear(512, 10))\n",
    "#model.add_module(\"sigmoid\", torch.nn.Sigmoid())\n",
    "\n",
    "model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-02 *\n",
       " -7.8055 -1.4542 -4.6459 -7.2926  2.7837 -6.3223  4.4707 -7.7274 -1.2790 -6.8382\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(torch.FloatTensor(X_val[:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda(0)\n",
    "    y_batch = Variable(torch.LongTensor(y_batch)).cuda(0)\n",
    "    logits = model(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Training __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(X, y, batchsize, shuffle=False):\n",
    "    indices = np.arange(len(X))\n",
    "    if shuffle: \n",
    "        indices = np.random.permutation(indices)\n",
    "    for start in trange(0, len(indices), batchsize):\n",
    "        ix = indices[start: start + batchsize]\n",
    "        yield X[ix], y[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pandas import ewma\n",
    "from IPython import display        \n",
    "        \n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3 / 2)\n",
    "\n",
    "num_epochs = 95 # total amount of full passes over training data\n",
    "batch_size = 1024  # number of samples processed in one SGD iteration\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGDCAYAAAAyM4nNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxH8BBRkQs1ZcaY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8fb0250828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 of 15 took 12.796s\n",
      "  training loss (in-iteration): \t0.268012\n",
      "  validation accuracy:\t\t84.61 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for X_batch, y_batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=True):\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.data.cpu().numpy()[0])\n",
    "        \n",
    "    # And a full pass over the validation data:\n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    y_score = []\n",
    "    for X_batch, y_batch in iterate_minibatches(X_val, y_val, batch_size, shuffle=False):\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda(0))\n",
    "        y_pred = logits.max(1)[1].data.cpu().numpy()\n",
    "        #val_accuracy.append(np.mean(y_batch == y_pred))\n",
    "        y_score.extend(y_pred)\n",
    "\n",
    "    y_score = np.asarray(y_score)\n",
    "    val_accuracy.append(np.mean(y_score == y_val))\n",
    "    # Visualize\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.xlabel(\"#Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(val_accuracy, 'b',label='val acc')\n",
    "    plt.plot(ewma(np.array(val_accuracy), span=10),'r',label='ewm val acc')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "            \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "#     print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "#         np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_accuracy[-1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 23.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t84.30 %\n",
      "Achievement unlocked: 110lvl Warlock!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    logits = model(Variable(torch.FloatTensor(X_batch)).cuda(0))\n",
    "    y_pred = logits.max(1)[1].data.cpu().numpy()\n",
    "    test_batch_acc.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 95:\n",
    "    print(\"Double-check, than consider applying for NIPS'17. SRSly.\")\n",
    "elif test_accuracy * 100 > 90:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 80:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 70:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 60:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `___ ___`, and here's my story\n",
    "\n",
    "A long ago in a galaxy far far away, when it was still more than an hour before deadline, i got an idea:\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "* brief text on what was\n",
    "* the original idea\n",
    "* and why it was so\n",
    "\n",
    "How could i be so naive?!\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "This thing has finally converged and\n",
    "* Some explaination about what were the results,\n",
    "* what worked and what didn't\n",
    "* most importantly - what next steps were taken, if any\n",
    "* and what were their respective outcomes\n",
    "\n",
    "##### Finally, after __  iterations, __ mugs of [tea/coffee]\n",
    "* what was the final architecture\n",
    "* as well as training method and tricks\n",
    "\n",
    "That, having wasted ____ [minutes, hours or days] of my life training, got\n",
    "\n",
    "* accuracy on training: __\n",
    "* accuracy on validation: __\n",
    "* accuracy on test: __\n",
    "\n",
    "\n",
    "[an optional afterword and mortal curses on assignment authors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the beginning I knew I will build ConvNet, using typical architecture, of Conv->BN->Pool->Nonlinearity->Dropout.\n",
    "The only thing to find out was the right size of convs, about of this blocks, dropout rate.\n",
    "\n",
    "I have started with the net similar to above, but has inital layer of 5x5 conv, followed by maxpool after, as well as Dropouts that all have 0.5 drop rate, and only one Dense layer in the end.\n",
    "\n",
    "The resulted accuracy on validation of this setup was about 70% and what as worse, if was very unstable on validation set, whith predicted accuracy jumping. I first lowered the learning rate, but that did not help.\n",
    "\n",
    "Then, I removed first conv 5x5 and made it 3x3, as well as remove first maxpool(otherwise I get too small image).\n",
    "That already give me imporvement and made learning curve more stable.\n",
    "\n",
    "Followed by this, I added one more dense layer in the end and lowered the dropout rate in the middle of conv part. As a result, I got stable learning curve, whith OK accuracy, which you can see above. If I have time, I may be play with augmentation, since I am sure this + sligh modification of net can result in abot 90% accuracy.\n",
    "\n",
    "Currently, by final results are\n",
    "\n",
    "\n",
    "* loss on training: 0.26\n",
    "* accuracy on validation: 84.61%\n",
    "* accuracy on test: 84.30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
